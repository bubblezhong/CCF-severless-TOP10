{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# from sklearn.model_selection import KFold\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import  matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 常量定义\n",
    "NFOLDS = 5  # 交叉验证的折数\n",
    "SEQ_LEN = 5  # 序列长度\n",
    "WINDOW_SIZE = 2 * SEQ_LEN  # 窗口长度\n",
    "MODEL_N = 10  # 10个模型分别预测 CPU_USAGE_6...LAUNCHING_JOB_NUMS_10\n",
    "\n",
    "__author__ = 'siliconx'\n",
    "__version__ = '1.0.0'\n",
    "\n",
    "pd.options.display.max_columns = None  # 展示所有列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始数据\n",
    "RAW_TRAIN = '../data/train.csv'\n",
    "RAW_TEST = '../data/evaluation_public.csv'\n",
    "SAMPLE_SUBMIT = '../data/submit_example.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载原始数据\n",
    "train_df = pd.read_csv(RAW_TRAIN)\n",
    "test_df = pd.read_csv(RAW_TEST)\n",
    "# sample_df = pd.read_csv(SAMPLE_SUBMIT)\n",
    "\n",
    "train_df = train_df.sort_values(by=['QUEUE_ID', 'DOTTING_TIME']).reset_index(drop=True)\n",
    "test_df = test_df.sort_values(by=['ID', 'DOTTING_TIME']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display(train_df, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def digitalization(fields):\n",
    "    \"\"\"将非数值型域转换为数值型.\"\"\"\n",
    "    # 组合训练集和测试集，只用来构建编码器，不用来训练模型\n",
    "    df = pd.concat([train_df[fields], test_df[fields]], ignore_index=True)\n",
    "\n",
    "    for f in fields:\n",
    "        # 构建编码器\n",
    "        le = LabelEncoder()\n",
    "        le.fit(df[f])\n",
    "\n",
    "        # 设置新值\n",
    "        train_df[f] = le.transform(train_df[f])\n",
    "        test_df[f] = le.transform(test_df[f])\n",
    "        print('%s:' % f, le.classes_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_processing():\n",
    "    \"\"\"预处理.\"\"\"\n",
    "    print('Preprocessing...')\n",
    "\n",
    "    # 缺失值填充\n",
    "    # 经检验，为NaN的都是vm（通过QUEUE_ID查找）\n",
    "    train_df['RESOURCE_TYPE'].fillna('vm', inplace=True)\n",
    "\n",
    "    # 观察数据，填充0比较合理（NaN集中在数据前面，可能是由服务器尚未开始运行导致的）\n",
    "    train_df['DISK_USAGE'].fillna(0, inplace=True)\n",
    "\n",
    "    # 需要转换的列\n",
    "    fields = ['STATUS', 'QUEUE_TYPE', 'PLATFORM', 'RESOURCE_TYPE']\n",
    "\n",
    "    # 数值化\n",
    "    digitalization(fields)\n",
    "\n",
    "    # 重命名，原来的名字太长了\n",
    "    for df in [train_df, test_df]:\n",
    "        df.rename(columns={\n",
    "            'LAUNCHING_JOB_NUMS': 'LJOB',\n",
    "            'RUNNING_JOB_NUMS': 'RJOB',\n",
    "            'SUCCEED_JOB_NUMS': 'SJOB',\n",
    "            'CANCELLED_JOB_NUMS': 'CJOB',\n",
    "            'FAILED_JOB_NUMS': 'FJOB'\n",
    "        }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "pre_processing()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 特征工程"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 时间特征\n",
    "\n",
    "-- 把DOTTINGTIME转换为一天之内的时间"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in [train_df, test_df]:\n",
    "    t = pd.to_datetime(df['DOTTING_TIME'], unit='ms')\n",
    "\n",
    "    # 转成小时\n",
    "    df['DOTTING_TIME'] = t.dt.hour + t.dt.minute / 60\n",
    "#     df['DOTTING_TIME'] = t.dt.hour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 行统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "used_features = ['CPU_USAGE', 'MEM_USAGE', 'DISK_USAGE', 'LJOB', 'RJOB']\n",
    "\n",
    "# 分组，只用训练集数据做统计\n",
    "group_data = train_df.groupby(by=['QUEUE_ID'])[used_features]\n",
    "\n",
    "# 聚合函数\n",
    "methods = {\n",
    "    'AVG': 'mean',\n",
    "    'MEDIAN': 'median',\n",
    "    'MIN': 'min',\n",
    "    'MAX': 'max',\n",
    "    'STD': 'std',\n",
    "}\n",
    "\n",
    "for m in methods:\n",
    "    agg_data = group_data.agg(methods[m])\n",
    "    agg_data.fillna(method='ffill', inplace=True)\n",
    "    agg_data.fillna(0, inplace=True)\n",
    "    agg_data = agg_data.rename(lambda x: 'QUEUE_%s_%s' % (x, m), axis=1)\n",
    "    agg_data = agg_data.reset_index()\n",
    "\n",
    "    for df in [train_df, test_df]:\n",
    "        merged_data = df[['QUEUE_ID']].merge(agg_data, how='left', on=['QUEUE_ID'])\n",
    "        merged_data.drop(columns=['QUEUE_ID'], inplace=True)\n",
    "\n",
    "        # 插入新的列\n",
    "        for c in merged_data.columns:\n",
    "            df[c] = 0\n",
    "\n",
    "        # 赋值\n",
    "        df.loc[:, list(merged_data.columns)] = merged_data.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###    3.3 滑动窗口构造数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 需要滑动的数值特征\n",
    "num_features = ['CPU_USAGE', 'MEM_USAGE', 'DISK_USAGE',\n",
    "                'LJOB', 'RJOB', 'SJOB', 'CJOB', 'FJOB']\n",
    "\n",
    "# 需要预测的值\n",
    "y_features = ['CPU_USAGE', 'LJOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 生成测试集时间窗数据\n",
    "for i in range(SEQ_LEN): # 5\n",
    "    for sf in num_features:\n",
    "        new_f = '%s_%d' % (sf, i+1)\n",
    "        test_df[new_f] = test_df[sf].shift(-i)\n",
    "\n",
    "# 删除原来的列\n",
    "test_df.drop(columns=num_features, inplace=True)\n",
    "\n",
    "# 只取每个ID的第一条数据\n",
    "test_df = test_df.groupby(by='ID', as_index=False).first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# 生成训练集时间窗数据\n",
    "temp = pd.DataFrame()\n",
    "qids = sorted(train_df['QUEUE_ID'].unique())\n",
    "\n",
    "for qid in tqdm(qids):  # 按QUEUE_ID进行处理\n",
    "    queue = train_df[train_df['QUEUE_ID'] == qid].copy(deep=True)\n",
    "\n",
    "    # 生成时间窗数据\n",
    "    for i in range(SEQ_LEN):\n",
    "        for sf in num_features:\n",
    "            new_f = '%s_%d' % (sf, i+1)\n",
    "            queue[new_f] = queue[sf].shift(-i)\n",
    "\n",
    "    # 处理需要预测的值\n",
    "    for i in range(SEQ_LEN):\n",
    "        for y in y_features:\n",
    "            new_y = '%s_%d' % (y, i+SEQ_LEN+1)\n",
    "            queue[new_y] = queue[y].shift(-i-SEQ_LEN)\n",
    "\n",
    "    # 删除原来的列\n",
    "    queue.drop(columns=num_features, inplace=True)\n",
    "\n",
    "    # 对于每个QUEUE_ID，丢弃最后10条有NAN值的数据\n",
    "    queue = queue.head(queue.shape[0]-WINDOW_SIZE)\n",
    "    temp = temp.append(queue)\n",
    "\n",
    "# 重设索引\n",
    "train_df = temp.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 列统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cpu_usages = []\n",
    "mem_usages = []\n",
    "disk_usages = []\n",
    "ljobs = []\n",
    "rjobs = []\n",
    "\n",
    "for i in range(SEQ_LEN):  # 5 \n",
    "    postfix = '_%d' % (i + 1)\n",
    "    cpu_usages.append('CPU_USAGE'+postfix)\n",
    "    mem_usages.append('MEM_USAGE'+postfix)\n",
    "    disk_usages.append('DISK_USAGE'+postfix)\n",
    "    ljobs.append('LJOB'+postfix)\n",
    "    rjobs.append('RJOB'+postfix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mem_usages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for df in [train_df, test_df]:\n",
    "    # zheng.heng baseline给的特征\n",
    "    df['USED_CPU'] = df['CU'] * df['CPU_USAGE_5'] / 100\n",
    "    df['USED_MEM'] = 4 * df['CU'] * df['MEM_USAGE_5'] / 100\n",
    "    df['TO_RUN_JOBS'] = df['LJOB_5'] - df['RJOB_5']\n",
    "    df.loc[df['TO_RUN_JOBS'] < 0, 'TO_RUN_JOBS'] = 0\n",
    "\n",
    "    # zheng.heng baseline中的新的列特征\n",
    "    pairs = [\n",
    "        ('CPU', 'CPU_USAGE', cpu_usages),\n",
    "        ('MEM', 'MEM_USAGE', mem_usages),\n",
    "        ('DISK', 'DISK_USAGE', disk_usages),\n",
    "        ('LJOB', 'LJOB', ljobs),\n",
    "        ('RJOB', 'RJOB', rjobs),\n",
    "    ]\n",
    "\n",
    "    for short_name, f, usages in pairs:\n",
    "        df[short_name+'_AVG'] = df[usages].mean(axis=1)\n",
    "        df[short_name+'_STD'] = df[usages].std(axis=1)\n",
    "        df[short_name+'_MAX'] = df[usages].max(axis=1)\n",
    "        df[short_name+'_DIFF'] = df['%s_5' % f] - df['%s_1' % f]\n",
    "        \n",
    "        \n",
    "    df['delta_CPU_AVG_CPU_USAGE_5'] = df['CPU_AVG'] - df['CPU_USAGE_5']\n",
    "    df['delta_CPU_AVG_CPU_USAGE_MAX'] = df['CPU_AVG'] - df['CPU_MAX']       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns[-20:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 滑窗统计特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 行内统计特征\n",
    "# # 行内统计特征\n",
    "# def stat_feat(data,step,col):\n",
    "# #     print(step)\n",
    "#     data['mean'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step+1)]].mean(axis=1)\n",
    "#     data['std'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step+1)]].std(axis=1)\n",
    "#     data['max'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step+1)]].max(axis=1)\n",
    "#     data[f'{col}_{step+1}_'+'mean'+col+'_'+str(step)] = data[f'{col}_{step+1}'] - data['mean'+col+'_'+str(step)]\n",
    "#     data['max'+col+'_'+str(step)+'mean'+col+'_'+str(step)] = data['max'+col+'_'+str(step)] - data['mean'+col+'_'+str(step)]\n",
    "\n",
    "#     #     if step < 6:\n",
    "# #         data['diff_1'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_1']\n",
    "# #         if step  > 2:\n",
    "# #             data['diff_2'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_2']\n",
    "# #         if step > 3:    \n",
    "# #             data['diff_3'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_3']\n",
    "# #         if step > 4:   \n",
    "# #             data['diff_4'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_4']\n",
    "\n",
    "# #     if (step >1) & (step < 6):\n",
    "# #         data['diff'+col+str(step)+str(step-1)] = data[f'{col}_{step}'] - data[f'{col}_{step-1}']\n",
    "#     return data    \n",
    "\n",
    "def stat_feat(data,step,col):\n",
    "#     print(step)\n",
    "    data['mean'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].mean(axis=1)\n",
    "    data['std'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].std(axis=1)\n",
    "    data['max'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].max(axis=1)\n",
    "    if step < 6:\n",
    "        data['diff_1'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_1']\n",
    "        if step  > 2:\n",
    "            data['diff_2'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_2']\n",
    "        if step > 3:    \n",
    "            data['diff_3'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_3']\n",
    "        if step > 4:   \n",
    "            data['diff_4'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_4']\n",
    "\n",
    "    if (step >1) & (step < 6):\n",
    "        data['diff'+col+str(step)+str(step-1)] = data[f'{col}_{step}'] - data[f'{col}_{step-1}']\n",
    "    return data   \n",
    "#,'LJOB','RJOB','SJOB','CJOB', 'FJOB',\n",
    "for c in tqdm(['MEM_USAGE','CPU_USAGE','DISK_USAGE']):\n",
    "    for s in range(2,5):\n",
    "        train_df = stat_feat(train_df,s,c)\n",
    "        test_df = stat_feat(test_df,s,c)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 特征过滤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去掉无用列   'QUEUE_ID',\n",
    "useless = [ \n",
    "    'PLATFORM', 'RESOURCE_TYPE', 'STATUS',\n",
    "]\n",
    "\n",
    "train_df.drop(columns=useless, inplace=True)\n",
    "test_df.drop(columns=useless, inplace=True)\n",
    "\n",
    "# display(train_df, test_df)\n",
    "# df_test.QUEUE_ID.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def run_lgb_qid(df_train, df_test, target, qid):\n",
    "    feature_names = list(\n",
    "        filter(lambda x: x not in ['QUEUE_ID', 'CU', 'QUEUE_TYPE'] + [f'CPU_USAGE_{i}' for i in range(6,11)]+\n",
    "               [f'LJOB_{i}' for i in range(6,11)], \n",
    "               df_train.columns))\n",
    "    \n",
    "    # 提取 QUEUE_ID 对应的数据集\n",
    "    df_train = df_train[df_train.QUEUE_ID == qid]\n",
    "    df_test = df_test[df_test.QUEUE_ID == qid]\n",
    "    \n",
    "    print(f\"QUEUE_ID:{qid}, target:{target}, train:{len(df_train)}, test:{len(df_test)}\")\n",
    "    \n",
    "    model = lgb.LGBMRegressor(num_leaves=20,\n",
    "#                 metric = 'mea',\n",
    "#                 objective=custom_asymmetric_train,\n",
    "                  max_depth=4,\n",
    "                  learning_rate=0.08,\n",
    "                  n_estimators=10000,\n",
    "                  subsample=0.9,\n",
    "                  feature_fraction=0.8,\n",
    "                  reg_alpha=0.6,\n",
    "                  reg_lambda=1.2,\n",
    "                  random_state=42)\n",
    "    oof = []\n",
    "    prediction = df_test[['ID', 'QUEUE_ID']]\n",
    "    prediction[target] = 0\n",
    "    \n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "    for fold_id, (trn_idx, val_idx) in enumerate(kfold.split(df_train, df_train[target])):\n",
    "        \n",
    "        X_train = df_train.iloc[trn_idx][feature_names]\n",
    "        Y_train = df_train.iloc[trn_idx][target]\n",
    "        X_val = df_train.iloc[val_idx][feature_names]\n",
    "        Y_val = df_train.iloc[val_idx][target]\n",
    "        \n",
    "        lgb_model = model.fit(X_train, \n",
    "                    Y_train,\n",
    "                    eval_names=['train', 'valid'],\n",
    "                    eval_set=[(X_train, Y_train), (X_val, Y_val)],\n",
    "                    verbose=100,\n",
    "#                     eval_metric= 'mse',  # 'mse',\n",
    "                    early_stopping_rounds=20)\n",
    "        \n",
    "        pred_val = lgb_model.predict(X_val, num_iteration=lgb_model.best_iteration_)\n",
    "        df_oof = df_train.iloc[val_idx][[target, 'QUEUE_ID']].copy()\n",
    "        df_oof['pred'] = pred_val\n",
    "        oof.append(df_oof)\n",
    "        \n",
    "        lgb.plot_importance(lgb_model, max_num_features=20)\n",
    "        plt.show()\n",
    "        \n",
    "        pred_test = lgb_model.predict(df_test[feature_names], num_iteration=lgb_model.best_iteration_)\n",
    "        prediction[target] += pred_test / kfold.n_splits\n",
    "        \n",
    "        del lgb_model, pred_val, pred_test, X_train, Y_train, X_val, Y_val\n",
    "        gc.collect()\n",
    "        \n",
    "    df_oof = pd.concat(oof)\n",
    "    score_mse = mean_squared_error(df_oof[target], df_oof['pred'])\n",
    "    score_mae = mean_absolute_error(df_oof[target], df_oof['pred'])\n",
    "    print('MSE:', score_mse,'MAE:', score_mae)\n",
    "\n",
    "    return prediction, score_mse,score_mae\n",
    "predictions = list()\n",
    "scores_mse = list()\n",
    "scores_mae = list()\n",
    "\n",
    "for qid in tqdm(test_df.QUEUE_ID.unique()):    \n",
    "    df = pd.DataFrame()\n",
    "    for t in [f'CPU_USAGE_{i}' for i in range(6,11)]:\n",
    "        prediction, score_mse, score_mae = run_lgb_qid(train_df, test_df, target=t, qid=qid)\n",
    "        if t == 'CPU_USAGE_6':\n",
    "            df = prediction.copy()\n",
    "        else:\n",
    "            df = pd.merge(df, prediction, on=['ID', 'QUEUE_ID'], how='left')            \n",
    "        scores_mse.append(score_mse)\n",
    "        scores_mae.append(score_mae)\n",
    "\n",
    "    predictions.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "print('mean MAE score: ', np.mean(scores_mse))\n",
    "\n",
    "print('mean MEA score: ', np.mean(scores_mae))\n",
    "\n",
    "print('online MSE score: ', 1-np.mean(scores_mae)/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predictions\n",
    "print('mean MAE score: ', np.mean(scores_mse))\n",
    "\n",
    "print('mean MEA score: ', np.mean(scores_mae))\n",
    "\n",
    "print('online MSE score: ', 1-np.mean(scores_mae)/100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.concat(predictions)\n",
    "\n",
    "sub = sub.sort_values(by='ID').reset_index(drop=True)\n",
    "sub.drop(['QUEUE_ID'], axis=1, inplace=True)\n",
    "sub.columns = ['ID'] + [f'CPU_USAGE_{i}' for i in range(1,6)]\n",
    "\n",
    "# 全置 0 都比训练出来的结果好\n",
    "for col in [f'LAUNCHING_JOB_NUMS_{i}' for i in range(1,6)]:\n",
    "    sub[col] = 0\n",
    "    \n",
    "sub = sub[['ID',\n",
    "           'CPU_USAGE_1', 'LAUNCHING_JOB_NUMS_1', \n",
    "           'CPU_USAGE_2', 'LAUNCHING_JOB_NUMS_2', \n",
    "           'CPU_USAGE_3', 'LAUNCHING_JOB_NUMS_3', \n",
    "           'CPU_USAGE_4', 'LAUNCHING_JOB_NUMS_4', \n",
    "           'CPU_USAGE_5', 'LAUNCHING_JOB_NUMS_5']]\n",
    "\n",
    "print(sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 注意: 提交要求预测结果需为非负整数, 包括 ID 也需要是整数\n",
    "\n",
    "sub['ID'] = sub['ID'].astype(int)\n",
    "\n",
    "for col in [i for i in sub.columns if i != 'ID']:\n",
    "    sub[col] = sub[col].apply(np.floor)\n",
    "    sub[col] = sub[col].apply(lambda x: 0 if x<0 else x)\n",
    "    sub[col] = sub[col].apply(lambda x: 100 if x>100 else x)\n",
    "    sub[col] = sub[col].astype(int)\n",
    "    \n",
    "sub.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.read_csv('./319.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = test_df[test_df.QUEUE_ID==85153]# 'CPU_USAGE_1','CPU_USAGE_2','CPU_USAGE_3','CPU_USAGE_4','CPU_USAGE_5'\n",
    "tt = t[t['CPU_AVG']>40][['ID','CPU_AVG','CPU_STD','RJOB_STD']]\n",
    "cor = tt.merge(sub[['ID']+[f'CPU_USAGE_{i}' for i in range(1,6)]],on='ID',how='left')\n",
    "# cor = tt[tt.RJOB_STD == 0]\n",
    "cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [f'CPU_USAGE_{i}' for i in range(1,6)]:\n",
    "    cor.loc[:, col] = 0.1*cor[col]  + 0.8*cor['CPU_AVG']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub.ID.isin(cor.ID), cor.columns[-5:]] = cor.loc[:, cor.columns[-5:]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub.ID.isin(cor.ID), cor.columns[-5:]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv('baseline_320_jiaoz.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.loc[sub.ID.isin(cor.ID), cor.columns[-5:]] .shape,cor.loc[:, ['CPU_USAGE_1', 'CPU_USAGE_2', 'CPU_USAGE_3', 'CPU_USAGE_4', 'CPU_USAGE_5']].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df.columns[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.ID.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tmp.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y_true, Y_preds):\n",
    "    \"\"\"赛题给的评估函数.\"\"\"\n",
    "    # shape: (n, 10)\n",
    "    if not isinstance(Y_true, np.ndarray):\n",
    "        Y_true = Y_true.to_numpy()\n",
    "\n",
    "    if not isinstance(Y_preds, np.ndarray):\n",
    "        Y_preds = Y_preds.to_numpy()\n",
    "\n",
    "    dist = 0  # DIST_k\n",
    "    for i in range(MODEL_N//2):\n",
    "        cpu_true, job_true = Y_true[:, i*2], Y_true[:, i*2+1]  # shape: (n,)\n",
    "        cpu_preds, job_preds = Y_preds[:, i*2], Y_preds[:, i*2+1]  # shape: (n,)\n",
    "        max_job = np.max((job_true, job_preds), axis=0)\n",
    "\n",
    "        # 防止分母为0（当分母为0是，分子也为0，所以可以把分母0设为1）\n",
    "        max_job[max_job == 0] = 1.0\n",
    "        dist += 0.9 * np.abs((cpu_preds - cpu_true) / 100) + 0.1 * np.abs((job_true - job_true) / max_job)\n",
    "\n",
    "    score = 1 - dist.mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(Y_true, Y_preds):\n",
    "    \"\"\"赛题给的评估函数.\"\"\"\n",
    "    # shape: (n, 10)\n",
    "    if not isinstance(Y_true, np.ndarray):\n",
    "        Y_true = Y_true.to_numpy()\n",
    "\n",
    "    if not isinstance(Y_preds, np.ndarray):\n",
    "        Y_preds = Y_preds.to_numpy()\n",
    "\n",
    "    dist = 0  # DIST_k\n",
    "#     print('Y_preds',Y_preds)\n",
    "    for i in range(MODEL_N//2):\n",
    "        cpu_true, job_true = Y_true[:, i*2], Y_true[:, i*2+1]  # shape: (n,)\n",
    "        cpu_preds, job_preds = Y_preds[:, i*2], Y_preds[:, i*2+1]  # shape: (n,)\n",
    "        max_job = np.max((job_true, job_preds), axis=0)\n",
    "\n",
    "        # 防止分母为0（当分母为0是，分子也为0，所以可以把分母0设为1）\n",
    "        max_job[max_job == 0] = 1.0\n",
    "        dist += 0.9 * np.abs((cpu_preds - cpu_true) / 100) + 0.1 * np.abs((job_preds - job_true) / max_job)\n",
    "\n",
    "    score = 1 - dist.mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean_oof = np.zeros((train_df.shape[0], 10))\n",
    "# # list(train_df['LJOB_AVG'])\n",
    "# for i in range(5): # \n",
    "#     mean_oof[:,2*i]=list(train_df['CPU_AVG'])  # + list(train_df['CPU_STD'])\n",
    "#     mean_oof[:,2*i+1]=  0 #list(train_df['LJOB_AVG']) # 0# 0\n",
    "# for i in range(5):\n",
    "#     new_oof[:,2*i]=oof[i]\n",
    "#     new_oof[:,2*i+1]=0 # list(train_df['LJOB_AVG'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# oof"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 计算验证集分数\n",
    "oof_score = evaluate(Y_train, oof)\n",
    "print('oof score = %.6f' % oof_score)  # 0.909830    0.909663  0.8838561580"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = sample_df.astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('baseline_311_cmodel.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df.to_csv('../submit/baseline_311.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 行内统计特征\n",
    "# # 行内统计特征\n",
    "# def stat_feat(data,step,col):\n",
    "# #     print(step)\n",
    "#     data['mean'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].mean(axis=1)\n",
    "#     data['std'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].std(axis=1)\n",
    "#     data['max'+col+'_'+str(step)] = data[[f'{col}_{i}' for i in range(1,step)]].max(axis=1)\n",
    "#     if step < 6:\n",
    "#         data['diff_1'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_1']\n",
    "#         if step  > 2:\n",
    "#             data['diff_2'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_2']\n",
    "#         if step > 3:    \n",
    "#             data['diff_3'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_3']\n",
    "#         if step > 4:   \n",
    "#             data['diff_4'+col+'_'+str(step)] = data[f'{col}_{step}'] - data[f'{col}_4']\n",
    "\n",
    "#     if (step >1) & (step < 6):\n",
    "#         data['diff'+col+str(step)+str(step-1)] = data[f'{col}_{step}'] - data[f'{col}_{step-1}']\n",
    "#     return data    \n",
    "# #,'LJOB','RJOB','SJOB','CJOB', 'FJOB',\n",
    "# for c in tqdm(['MEM_USAGE','CPU_USAGE','DISK_USAGE']):\n",
    "#     for s in range(2,6):\n",
    "#         train_df = stat_feat(train_df,s,c)\n",
    "#         test_df = stat_feat(test_df,s,c)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
